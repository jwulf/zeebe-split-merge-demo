import uuid from "uuid";
import { BpmnParser, ZBClient } from "zeebe-node-0.17a";

const zbc = new ZBClient("localhost:26500");

// Autogenerated constants for split-inputs.bpmn, do-processing.bpmn

enum TaskType {
  AGGREGATE_RESULT = "aggregate-result",
  DO_PROCESSING = "do-processing",
  MESSAGE_RESULT = "message-result",
  OUTPUT = "output",
  PROCESS_TIMEOUT = "process-timeout",
  SPLIT_INPUTS = "split-inputs"
}

enum MessageName {
  FILE_PROCESSED = "file-processed"
}

// @TODO Complete implementation

/*
// Helper to generate TypeScript types from BPMN
(async () => {
  console.log(
    await BpmnParser.generateConstantsForBpmnFiles([
      "./bpmn/split-inputs.bpmn",
      "./bpmn/do-processing.bpmn"
    ])
  );
})();
*/

test("./bpmn/split-inputs.bpmn", ["./bpmn/do-processing.bpmn"]);

let processingWorkflowId: string;
export async function test(
  bpmnFileToStart: string,
  dependencies: string[] = []
) {
  const files = [
    "./files/test1.json",
    "./files/test2.json",
    "./files/test3.json"
  ];
  const processId = await deployWorkflow(bpmnFileToStart);
  // Allows for multiple dependencies, but we have just one in this case
  processingWorkflowId = (await Promise.all(
    dependencies.map(d => deployWorkflow(d))
  ))[0];
  if (createWorkers()) {
    const processKey = uuid.v4();

    await zbc.createWorkflowInstance(processId, {
      processKey,
      files,
      results: [],
      totalToDo: files.length
    });
  }
}

async function deployWorkflow(bpmnFile: string) {
  await zbc.deployWorkflow(bpmnFile, { redeploy: true });

  // Parse the process id from the bpmn file
  const pid: string = (BpmnParser.parseBpmn(bpmnFile) as any)[0][
    "bpmn:definitions"
  ]["bpmn:process"]["attr"]["@_id"];
  return pid;
}

function createWorkers() {
  const workers: any[] = [];
  workers.push({
    splitInputsWorker: zbc.createWorker(
      "split-inputs-worker",
      TaskType.SPLIT_INPUTS,
      async (job, complete) => {
        const { files, processKey } = job.variables;

        await Promise.all(
          files.map(f =>
            zbc.createWorkflowInstance(processingWorkflowId, {
              processKey,
              file: f
            })
          )
        );

        complete(job.variables);
      }
    )
  });

  workers.push({
    doProcessingWorker: zbc.createWorker(
      "do-processing-worker",
      TaskType.DO_PROCESSING,
      async (job, complete) => {
        const zbc = new ZBClient("localhost:26500");
        const { file, processKey } = job.variables;
        const rawFile = require(file);
        const transformedContent = rawFile.content.toUpperCase();
        await zbc.publishMessage({
          correlationKey: processKey,
          messageId: uuid.v4(),
          name: "file-processed",
          timeToLive: 1000,
          variables: {
            transformedFile: { content: transformedContent }
          }
        });
        complete();
      }
    )
  });

  workers.push({
    outputWorker: zbc.createWorker(
      "output-worker",
      TaskType.OUTPUT,
      (job, complete) => {
        const taskName = job.jobHeaders.elementId;
        console.log("%s: %j", taskName, job.variables);
        complete(job.variables);
      }
    )
  });

  workers.push({
    aggregateResultWorker: zbc.createWorker(
      "aggregate-result-worker",
      TaskType.AGGREGATE_RESULT,
      (job, complete) => {
        const results = job.variables.results || [];
        results.push(job.variables.transformedFile);
        const resultCount = results.length;
        const finishedProcessing = resultCount === job.variables.totalToDo;
        complete({
          ...job.variables,
          results,
          resultCount,
          finishedProcessing
        });
      }
    )
  });

  return workers;
}
